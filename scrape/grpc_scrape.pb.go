// Code generated by protoc-gen-go. DO NOT EDIT.
// source: grpc_scrape.proto

/*
Package plagiari_sm_grpc_scrape is a generated protocol buffer package.

Package name (~DNS)

It is generated from these files:
	grpc_scrape.proto

It has these top-level messages:
	RequestArticle
	RequestStream
	Content
	NLP
	Data
	Response
*/
package plagiari_sm_grpc_scrape

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

// RequestArticle for SimpleScrape
type RequestArticle struct {
	Feed string `protobuf:"bytes,1,opt,name=feed" json:"feed,omitempty"`
	Url  string `protobuf:"bytes,2,opt,name=url" json:"url,omitempty"`
}

func (m *RequestArticle) Reset()                    { *m = RequestArticle{} }
func (m *RequestArticle) String() string            { return proto.CompactTextString(m) }
func (*RequestArticle) ProtoMessage()               {}
func (*RequestArticle) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *RequestArticle) GetFeed() string {
	if m != nil {
		return m.Feed
	}
	return ""
}

func (m *RequestArticle) GetUrl() string {
	if m != nil {
		return m.Url
	}
	return ""
}

// RequestStream for Scrape in Streaming mode (ex. svc-listen)
type RequestStream struct {
	Feed    string `protobuf:"bytes,1,opt,name=feed" json:"feed,omitempty"`
	Url     string `protobuf:"bytes,2,opt,name=url" json:"url,omitempty"`
	TweetID int64  `protobuf:"varint,3,opt,name=tweetID" json:"tweetID,omitempty"`
}

func (m *RequestStream) Reset()                    { *m = RequestStream{} }
func (m *RequestStream) String() string            { return proto.CompactTextString(m) }
func (*RequestStream) ProtoMessage()               {}
func (*RequestStream) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }

func (m *RequestStream) GetFeed() string {
	if m != nil {
		return m.Feed
	}
	return ""
}

func (m *RequestStream) GetUrl() string {
	if m != nil {
		return m.Url
	}
	return ""
}

func (m *RequestStream) GetTweetID() int64 {
	if m != nil {
		return m.TweetID
	}
	return 0
}

// Content of the Scraped Article or Stream
type Content struct {
	Title       string   `protobuf:"bytes,1,opt,name=title" json:"title,omitempty"`
	Excerpt     string   `protobuf:"bytes,2,opt,name=excerpt" json:"excerpt,omitempty"`
	Body        string   `protobuf:"bytes,3,opt,name=body" json:"body,omitempty"`
	Authors     []string `protobuf:"bytes,4,rep,name=authors" json:"authors,omitempty"`
	Sources     []string `protobuf:"bytes,5,rep,name=sources" json:"sources,omitempty"`
	Tags        []string `protobuf:"bytes,6,rep,name=tags" json:"tags,omitempty"`
	Categories  []string `protobuf:"bytes,7,rep,name=categories" json:"categories,omitempty"`
	PublishedAt string   `protobuf:"bytes,8,opt,name=publishedAt" json:"publishedAt,omitempty"`
	EditedAt    string   `protobuf:"bytes,9,opt,name=editedAt" json:"editedAt,omitempty"`
}

func (m *Content) Reset()                    { *m = Content{} }
func (m *Content) String() string            { return proto.CompactTextString(m) }
func (*Content) ProtoMessage()               {}
func (*Content) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{2} }

func (m *Content) GetTitle() string {
	if m != nil {
		return m.Title
	}
	return ""
}

func (m *Content) GetExcerpt() string {
	if m != nil {
		return m.Excerpt
	}
	return ""
}

func (m *Content) GetBody() string {
	if m != nil {
		return m.Body
	}
	return ""
}

func (m *Content) GetAuthors() []string {
	if m != nil {
		return m.Authors
	}
	return nil
}

func (m *Content) GetSources() []string {
	if m != nil {
		return m.Sources
	}
	return nil
}

func (m *Content) GetTags() []string {
	if m != nil {
		return m.Tags
	}
	return nil
}

func (m *Content) GetCategories() []string {
	if m != nil {
		return m.Categories
	}
	return nil
}

func (m *Content) GetPublishedAt() string {
	if m != nil {
		return m.PublishedAt
	}
	return ""
}

func (m *Content) GetEditedAt() string {
	if m != nil {
		return m.EditedAt
	}
	return ""
}

// NLP data of the Scraped Article or Stream
type NLP struct {
	Tokens    []string `protobuf:"bytes,1,rep,name=tokens" json:"tokens,omitempty"`
	StopWords []string `protobuf:"bytes,2,rep,name=stopWords" json:"stopWords,omitempty"`
}

func (m *NLP) Reset()                    { *m = NLP{} }
func (m *NLP) String() string            { return proto.CompactTextString(m) }
func (*NLP) ProtoMessage()               {}
func (*NLP) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{3} }

func (m *NLP) GetTokens() []string {
	if m != nil {
		return m.Tokens
	}
	return nil
}

func (m *NLP) GetStopWords() []string {
	if m != nil {
		return m.StopWords
	}
	return nil
}

// Data for the Response Object
type Data struct {
	Content *Content `protobuf:"bytes,1,opt,name=content" json:"content,omitempty"`
	Nlp     *NLP     `protobuf:"bytes,2,opt,name=nlp" json:"nlp,omitempty"`
}

func (m *Data) Reset()                    { *m = Data{} }
func (m *Data) String() string            { return proto.CompactTextString(m) }
func (*Data) ProtoMessage()               {}
func (*Data) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{4} }

func (m *Data) GetContent() *Content {
	if m != nil {
		return m.Content
	}
	return nil
}

func (m *Data) GetNlp() *NLP {
	if m != nil {
		return m.Nlp
	}
	return nil
}

// Response Object
type Response struct {
	// success, error
	Status string `protobuf:"bytes,1,opt,name=status" json:"status,omitempty"`
	// 200, 500
	Code int32 `protobuf:"varint,2,opt,name=code" json:"code,omitempty"`
	// message
	Message string `protobuf:"bytes,3,opt,name=message" json:"message,omitempty"`
	// data Object {}
	Data *Data `protobuf:"bytes,4,opt,name=data" json:"data,omitempty"`
}

func (m *Response) Reset()                    { *m = Response{} }
func (m *Response) String() string            { return proto.CompactTextString(m) }
func (*Response) ProtoMessage()               {}
func (*Response) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{5} }

func (m *Response) GetStatus() string {
	if m != nil {
		return m.Status
	}
	return ""
}

func (m *Response) GetCode() int32 {
	if m != nil {
		return m.Code
	}
	return 0
}

func (m *Response) GetMessage() string {
	if m != nil {
		return m.Message
	}
	return ""
}

func (m *Response) GetData() *Data {
	if m != nil {
		return m.Data
	}
	return nil
}

func init() {
	proto.RegisterType((*RequestArticle)(nil), "plagiari.sm.grpc.scrape.RequestArticle")
	proto.RegisterType((*RequestStream)(nil), "plagiari.sm.grpc.scrape.RequestStream")
	proto.RegisterType((*Content)(nil), "plagiari.sm.grpc.scrape.Content")
	proto.RegisterType((*NLP)(nil), "plagiari.sm.grpc.scrape.NLP")
	proto.RegisterType((*Data)(nil), "plagiari.sm.grpc.scrape.Data")
	proto.RegisterType((*Response)(nil), "plagiari.sm.grpc.scrape.Response")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for GRPCScrape service

type GRPCScrapeClient interface {
	// Endpoint Scrape
	Scrape(ctx context.Context, in *RequestStream, opts ...grpc.CallOption) (*Response, error)
	// Endpoint SimpleScrape
	SimpleScrape(ctx context.Context, in *RequestArticle, opts ...grpc.CallOption) (*Response, error)
}

type gRPCScrapeClient struct {
	cc *grpc.ClientConn
}

func NewGRPCScrapeClient(cc *grpc.ClientConn) GRPCScrapeClient {
	return &gRPCScrapeClient{cc}
}

func (c *gRPCScrapeClient) Scrape(ctx context.Context, in *RequestStream, opts ...grpc.CallOption) (*Response, error) {
	out := new(Response)
	err := grpc.Invoke(ctx, "/plagiari.sm.grpc.scrape.GRPCScrape/Scrape", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gRPCScrapeClient) SimpleScrape(ctx context.Context, in *RequestArticle, opts ...grpc.CallOption) (*Response, error) {
	out := new(Response)
	err := grpc.Invoke(ctx, "/plagiari.sm.grpc.scrape.GRPCScrape/SimpleScrape", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for GRPCScrape service

type GRPCScrapeServer interface {
	// Endpoint Scrape
	Scrape(context.Context, *RequestStream) (*Response, error)
	// Endpoint SimpleScrape
	SimpleScrape(context.Context, *RequestArticle) (*Response, error)
}

func RegisterGRPCScrapeServer(s *grpc.Server, srv GRPCScrapeServer) {
	s.RegisterService(&_GRPCScrape_serviceDesc, srv)
}

func _GRPCScrape_Scrape_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RequestStream)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GRPCScrapeServer).Scrape(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/plagiari.sm.grpc.scrape.GRPCScrape/Scrape",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GRPCScrapeServer).Scrape(ctx, req.(*RequestStream))
	}
	return interceptor(ctx, in, info, handler)
}

func _GRPCScrape_SimpleScrape_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(RequestArticle)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GRPCScrapeServer).SimpleScrape(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/plagiari.sm.grpc.scrape.GRPCScrape/SimpleScrape",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GRPCScrapeServer).SimpleScrape(ctx, req.(*RequestArticle))
	}
	return interceptor(ctx, in, info, handler)
}

var _GRPCScrape_serviceDesc = grpc.ServiceDesc{
	ServiceName: "plagiari.sm.grpc.scrape.GRPCScrape",
	HandlerType: (*GRPCScrapeServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Scrape",
			Handler:    _GRPCScrape_Scrape_Handler,
		},
		{
			MethodName: "SimpleScrape",
			Handler:    _GRPCScrape_SimpleScrape_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "grpc_scrape.proto",
}

func init() { proto.RegisterFile("grpc_scrape.proto", fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 464 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x8c, 0x53, 0x4f, 0x8b, 0xd4, 0x4e,
	0x10, 0xfd, 0x65, 0x33, 0x7f, 0x6b, 0x7e, 0x8a, 0x36, 0xa2, 0xcd, 0xb2, 0x4a, 0xcc, 0x41, 0xf7,
	0x14, 0x70, 0x04, 0x0f, 0x7a, 0x5a, 0x76, 0x41, 0x84, 0x65, 0x1d, 0x7a, 0x10, 0x2f, 0x82, 0xf4,
	0x24, 0x65, 0x36, 0x98, 0x49, 0xb7, 0xdd, 0x15, 0xd4, 0xb3, 0x9f, 0xcc, 0xcf, 0xe4, 0x17, 0x90,
	0xae, 0xf4, 0xe8, 0x7a, 0x18, 0xdd, 0x5b, 0xbd, 0x7a, 0xf5, 0x5e, 0xaa, 0x5f, 0xa7, 0xe1, 0x76,
	0xed, 0x6c, 0xf9, 0xde, 0x97, 0x4e, 0x5b, 0x2c, 0xac, 0x33, 0x64, 0xc4, 0x3d, 0xdb, 0xea, 0xba,
	0xd1, 0xae, 0x29, 0xfc, 0xb6, 0x08, 0x74, 0x31, 0xd0, 0xf9, 0x33, 0xb8, 0xa9, 0xf0, 0x53, 0x8f,
	0x9e, 0x4e, 0x1c, 0x35, 0x65, 0x8b, 0x42, 0xc0, 0xe8, 0x03, 0x62, 0x25, 0x93, 0x2c, 0x39, 0x9e,
	0x2b, 0xae, 0xc5, 0x2d, 0x48, 0x7b, 0xd7, 0xca, 0x03, 0x6e, 0x85, 0x32, 0x7f, 0x0d, 0x37, 0xa2,
	0x6e, 0x4d, 0x0e, 0xf5, 0xf6, 0x7a, 0x32, 0x21, 0x61, 0x4a, 0x9f, 0x11, 0xe9, 0xd5, 0x99, 0x4c,
	0xb3, 0xe4, 0x38, 0x55, 0x3b, 0x98, 0xff, 0x48, 0x60, 0x7a, 0x6a, 0x3a, 0xc2, 0x8e, 0xc4, 0x1d,
	0x18, 0x53, 0x43, 0x2d, 0x46, 0xb3, 0x01, 0x04, 0x2d, 0x7e, 0x29, 0xd1, 0x59, 0x8a, 0x8e, 0x3b,
	0x18, 0xbe, 0xbd, 0x31, 0xd5, 0x57, 0xb6, 0x9c, 0x2b, 0xae, 0xc3, 0xb4, 0xee, 0xe9, 0xd2, 0x38,
	0x2f, 0x47, 0x59, 0x1a, 0xa6, 0x23, 0x0c, 0x8c, 0x37, 0xbd, 0x2b, 0xd1, 0xcb, 0xf1, 0xc0, 0x44,
	0x18, 0x7c, 0x48, 0xd7, 0x5e, 0x4e, 0xb8, 0xcd, 0xb5, 0x78, 0x00, 0x50, 0x6a, 0xc2, 0xda, 0xb8,
	0x06, 0xbd, 0x9c, 0x32, 0x73, 0xa5, 0x23, 0x32, 0x58, 0xd8, 0x7e, 0xd3, 0x36, 0xfe, 0x12, 0xab,
	0x13, 0x92, 0x33, 0x5e, 0xe1, 0x6a, 0x4b, 0x1c, 0xc2, 0x0c, 0xab, 0x86, 0x98, 0x9e, 0x33, 0xfd,
	0x0b, 0xe7, 0x2f, 0x20, 0xbd, 0x38, 0x5f, 0x89, 0xbb, 0x30, 0x21, 0xf3, 0x11, 0x3b, 0x2f, 0x13,
	0xfe, 0x40, 0x44, 0xe2, 0x08, 0xe6, 0x9e, 0x8c, 0x7d, 0x6b, 0x5c, 0xe5, 0xe5, 0x01, 0x53, 0xbf,
	0x1b, 0xb9, 0x83, 0xd1, 0x99, 0x26, 0x2d, 0x9e, 0xc3, 0xb4, 0x1c, 0x92, 0xe3, 0xc0, 0x16, 0xcb,
	0xac, 0xd8, 0x73, 0xdd, 0x45, 0x4c, 0x58, 0xed, 0x04, 0xa2, 0x80, 0xb4, 0x6b, 0x2d, 0x07, 0xba,
	0x58, 0x1e, 0xed, 0xd5, 0x5d, 0x9c, 0xaf, 0x54, 0x18, 0xcc, 0xbf, 0x25, 0x30, 0x53, 0xe8, 0xad,
	0xe9, 0x3c, 0x86, 0xb5, 0x3d, 0x69, 0xea, 0x7d, 0xbc, 0xa8, 0x88, 0x42, 0x8e, 0xa5, 0xa9, 0x90,
	0x5d, 0xc7, 0x8a, 0xeb, 0x90, 0xfa, 0x16, 0xbd, 0xd7, 0x35, 0xc6, 0x6b, 0xda, 0x41, 0xf1, 0x04,
	0x46, 0x95, 0x26, 0x2d, 0x47, 0xbc, 0xc3, 0xfd, 0xbd, 0x3b, 0x84, 0xb3, 0x2a, 0x1e, 0x5d, 0x7e,
	0x4f, 0x00, 0x5e, 0xaa, 0xd5, 0xe9, 0x9a, 0x19, 0xf1, 0x06, 0x26, 0xb1, 0x7a, 0xb4, 0x57, 0xfd,
	0xc7, 0xdf, 0x7a, 0xf8, 0xf0, 0x2f, 0x73, 0xc3, 0xe1, 0xf2, 0xff, 0xc4, 0x3b, 0xf8, 0x7f, 0xdd,
	0x6c, 0x6d, 0x8b, 0xd1, 0xfc, 0xf1, 0xbf, 0xcc, 0xe3, 0x13, 0xba, 0x96, 0xfb, 0x66, 0xc2, 0x2f,
	0xf3, 0xe9, 0xcf, 0x00, 0x00, 0x00, 0xff, 0xff, 0xc9, 0x94, 0xbd, 0xdf, 0xae, 0x03, 0x00, 0x00,
}
